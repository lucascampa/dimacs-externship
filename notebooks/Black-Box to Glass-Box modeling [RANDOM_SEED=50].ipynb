{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2024a6ab-71ac-4e03-9e91-7f9e2de5056a",
   "metadata": {},
   "source": [
    "See [Black-Box to Glass-Box modeling \\[RANDOM_SEED=42\\]](Black-Box%20to%20Glass-Box%20modeling%20%5BRANDOM_SEED%3D42%5D.ipynb) for an overview and steps 1 through 6\n",
    "# Steps\n",
    "7. Run SPLIT -> lookahead depth = 2, max_depth = 5, lambda = 0.005, 0.006, 0.007, 0.008, 0.009, 0.01\n",
    "8. Run XGBoost to select features -> baseline iteration, then cumulative gain = 80%, 90%, 95% , 97.5%, 99%\n",
    "9. Run SPLIT with the selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3cf716-3e42-47ad-b018-ed8f7c768894",
   "metadata": {},
   "source": [
    "## Get the training, validation, and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0985aa-937b-49b9-8836-02e9ad384b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dimex as dx\n",
    "\n",
    "RANDOM_SEED = 50\n",
    "\n",
    "test_encoded_filename = '../airline-passenger-satisfaction/test_clean_encoded.csv'\n",
    "test_encoded = pd.read_csv(test_encoded_filename, index_col=0)\n",
    "\n",
    "x_val, x_test, y_val, y_test = dx.split_dataset(test_encoded, test_size=2/3, random_state=RANDOM_SEED)\n",
    "\n",
    "train_encoded_filename = '../airline-passenger-satisfaction/train_clean_encoded_balanced.csv'\n",
    "train_encoded = pd.read_csv(train_encoded_filename, index_col=0)\n",
    "\n",
    "labels = train_encoded.columns[-1]\n",
    "\n",
    "x_train_balanced, y_train_balanced = train_encoded.drop(columns=[labels]), train_encoded[labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e16d33-3767-47a1-8e86-14d50f43deed",
   "metadata": {},
   "source": [
    "## 7 - Run SPLIT -> Lookahead depth = 2, max depth = 5, lambda = 0.005-0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cea07c1-e740-416a-8506-0fe42e1a9deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>leaves</th>\n",
       "      <th>training runtime (s)</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>5.32</td>\n",
       "      <td>88.12%</td>\n",
       "      <td>89.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006</td>\n",
       "      <td>6</td>\n",
       "      <td>5.19</td>\n",
       "      <td>88.12%</td>\n",
       "      <td>89.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007</td>\n",
       "      <td>6</td>\n",
       "      <td>5.16</td>\n",
       "      <td>88.12%</td>\n",
       "      <td>89.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008</td>\n",
       "      <td>5</td>\n",
       "      <td>5.13</td>\n",
       "      <td>87.27%</td>\n",
       "      <td>88.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009</td>\n",
       "      <td>5</td>\n",
       "      <td>5.16</td>\n",
       "      <td>87.27%</td>\n",
       "      <td>88.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>5</td>\n",
       "      <td>5.15</td>\n",
       "      <td>87.27%</td>\n",
       "      <td>88.38%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lambda  leaves training runtime (s) training accuracy validation accuracy\n",
       "0   0.005       6                 5.32            88.12%              89.06%\n",
       "1   0.006       6                 5.19            88.12%              89.06%\n",
       "2   0.007       6                 5.16            88.12%              89.06%\n",
       "3   0.008       5                 5.13            87.27%              88.38%\n",
       "4   0.009       5                 5.16            87.27%              88.38%\n",
       "5   0.010       5                 5.15            87.27%              88.38%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iteration 0 -> Lambda = 0.005\n",
    "model_0, tree_0, model_data_0 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.005)\n",
    "train_prediction_0 = dx.prediction_split(model_0, x_train_balanced, y_train_balanced)\n",
    "val_prediction_0 = dx.prediction_split(model_0, x_val, y_val)\n",
    "\n",
    "# Iteration 1 -> Lambda = 0.006\n",
    "model_1, tree_1, model_data_1 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.006)\n",
    "train_prediction_1 = dx.prediction_split(model_1, x_train_balanced, y_train_balanced)\n",
    "val_prediction_1 = dx.prediction_split(model_1, x_val, y_val)\n",
    "\n",
    "# Iteration 2 -> Lambda = 0.007\n",
    "model_2, tree_2, model_data_2 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.007)\n",
    "train_prediction_2 = dx.prediction_split(model_2, x_train_balanced, y_train_balanced)\n",
    "val_prediction_2 = dx.prediction_split(model_2, x_val, y_val)\n",
    "\n",
    "# Iteration 3 -> Lambda = 0.008\n",
    "model_3, tree_3, model_data_3 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.008)\n",
    "train_prediction_3 = dx.prediction_split(model_3, x_train_balanced, y_train_balanced)\n",
    "val_prediction_3 = dx.prediction_split(model_3, x_val, y_val)\n",
    "\n",
    "# Iteration 4 -> Lambda = 0.009\n",
    "model_4, tree_4, model_data_4 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.009)\n",
    "train_prediction_4 = dx.prediction_split(model_4, x_train_balanced, y_train_balanced)\n",
    "val_prediction_4 = dx.prediction_split(model_4, x_val, y_val)\n",
    "\n",
    "# Iteration 5 -> Lambda = 0.01\n",
    "model_5, tree_5, model_data_5 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.01)\n",
    "train_prediction_5 = dx.prediction_split(model_5, x_train_balanced, y_train_balanced)\n",
    "val_prediction_5 = dx.prediction_split(model_5, x_val, y_val)\n",
    "\n",
    "models_data = [model_data_0, model_data_1, model_data_2, model_data_3, model_data_4, model_data_5]\n",
    "train_predictions = [train_prediction_0, train_prediction_1, train_prediction_2, train_prediction_3, train_prediction_4, train_prediction_5]\n",
    "val_predictions = [val_prediction_0, val_prediction_1, val_prediction_2, val_prediction_3, val_prediction_4, val_prediction_5]\n",
    "\n",
    "split_results = []\n",
    "\n",
    "for i in range(6):\n",
    "    split_results.extend([{\"lambda\": models_data[i][\"lambda\"],\n",
    "                           \"leaves\": models_data[i][\"leaves\"],\n",
    "                           \"training runtime (s)\": format(models_data[i][\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_predictions[i][1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_predictions[i][1], \".2%\"),}])\n",
    "\n",
    "display(pd.DataFrame(split_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c08f194-93fd-45ce-ae18-0f425cc96029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda 0.005 tree: { feature: 0 [ left child: { prediction: 1, loss: 0.002058142563328147 }, right child: { feature: 8 [ left child: { feature: 1 [ left child: { feature: 3 [ left child: { prediction: 0, loss: 0.03891390189528465 }, right child: { prediction: 1, loss: 0.02518787421286106 }] }, right child: { prediction: 1, loss: 0.037398576736450195 }] }, right child: { feature: 2 [ left child: { prediction: 0, loss: 0.02133789099752903 }, right child: { prediction: 1, loss: 0.0 }] }] }] } \n",
      "\n",
      "lambda 0.006 tree: { feature: 0 [ left child: { prediction: 1, loss: 0.002058142563328147 }, right child: { feature: 8 [ left child: { feature: 1 [ left child: { feature: 3 [ left child: { prediction: 0, loss: 0.03891390189528465 }, right child: { prediction: 1, loss: 0.02518787421286106 }] }, right child: { prediction: 1, loss: 0.037398576736450195 }] }, right child: { feature: 2 [ left child: { prediction: 0, loss: 0.02133789099752903 }, right child: { prediction: 1, loss: 0.0 }] }] }] } \n",
      "\n",
      "lambda 0.007 tree: { feature: 0 [ left child: { prediction: 1, loss: 0.002058142563328147 }, right child: { feature: 8 [ left child: { feature: 1 [ left child: { feature: 3 [ left child: { prediction: 0, loss: 0.03891390189528465 }, right child: { prediction: 1, loss: 0.02518787421286106 }] }, right child: { prediction: 1, loss: 0.037398576736450195 }] }, right child: { feature: 2 [ left child: { prediction: 0, loss: 0.02133789099752903 }, right child: { prediction: 1, loss: 0.0 }] }] }] }\n"
     ]
    }
   ],
   "source": [
    "print(\"lambda\",models_data[0][\"lambda\"], \"tree:\", tree_0, \"\\n\")\n",
    "print(\"lambda\",models_data[1][\"lambda\"], \"tree:\", tree_1, \"\\n\")\n",
    "print(\"lambda\",models_data[2][\"lambda\"], \"tree:\", tree_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f27728-ebb6-46e7-b018-cb5638e5fc3d",
   "metadata": {},
   "source": [
    "Despite the different lambdas, the 3 trees are identical. Same number of leaves, same loss, same accuracy. I'm picking lambda = 0.007 because it keeps accuracy and tree size the same while giving the most regularization cushion against small shifts in data and pipeline or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb15b009-3d81-44d3-8962-0ef10b6642e2",
   "metadata": {},
   "source": [
    "## 8 - Run XGBoost -> baseline iteration, cumulative gain = 80%-99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ca9539-4870-448d-907e-bbc407242ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "      <th>number of features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>92.53%</td>\n",
       "      <td>93.99%</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cumulative gain = 80%</td>\n",
       "      <td>91.43%</td>\n",
       "      <td>92.72%</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cumulative gain = 90%</td>\n",
       "      <td>92.26%</td>\n",
       "      <td>93.65%</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cumulative gain = 95%</td>\n",
       "      <td>92.39%</td>\n",
       "      <td>93.76%</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cumulative gain = 97.5%</td>\n",
       "      <td>92.42%</td>\n",
       "      <td>93.80%</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cumulative gain = 99%</td>\n",
       "      <td>92.49%</td>\n",
       "      <td>93.92%</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 iteration training accuracy validation accuracy  \\\n",
       "0                 baseline            92.53%              93.99%   \n",
       "1    cumulative gain = 80%            91.43%              92.72%   \n",
       "2    cumulative gain = 90%            92.26%              93.65%   \n",
       "3    cumulative gain = 95%            92.39%              93.76%   \n",
       "4  cumulative gain = 97.5%            92.42%              93.80%   \n",
       "5    cumulative gain = 99%            92.49%              93.92%   \n",
       "\n",
       "   number of features  \n",
       "0                  23  \n",
       "1                   9  \n",
       "2                  13  \n",
       "3                  16  \n",
       "4                  17  \n",
       "5                  19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# baseline\n",
    "xgb_baseline, size_baseline, runtime_baseline = dx.train_xgb(x_train_balanced, y_train_balanced, random_state=RANDOM_SEED)\n",
    "y_train_pred_baseline, acc_baseline = dx.prediction_xgb(xgb_baseline, x_train_balanced, y_train_balanced)\n",
    "y_val_pred_baseline, acc_val_baseline = dx.prediction_xgb(xgb_baseline, x_val, y_val)\n",
    "\n",
    "gain_sorted, total_gain = dx.sort_by_gain(xgb_baseline)\n",
    "\n",
    "# cumulative gain = 80%\n",
    "xgb_0, size_0, runtime_0, features_0 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .8, random_state=RANDOM_SEED)\n",
    "y_train_pred_0, acc_0 = dx.prediction_xgb(xgb_0, x_train_balanced[features_0], y_train_balanced)\n",
    "y_val_pred_0, acc_val_0 = dx.prediction_xgb(xgb_0, x_val[features_0], y_val)\n",
    "\n",
    "# cumulative gain = 90%\n",
    "xgb_1, size_1, runtime_1, features_1 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .9, random_state=RANDOM_SEED)\n",
    "y_train_pred_1, acc_1 = dx.prediction_xgb(xgb_1, x_train_balanced[features_1], y_train_balanced)\n",
    "y_val_pred_1, acc_val_1 = dx.prediction_xgb(xgb_1, x_val[features_1], y_val)\n",
    "\n",
    "# cumulative gain = 95%\n",
    "xgb_2, size_2, runtime_2, features_2 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .95, random_state=RANDOM_SEED)\n",
    "y_train_pred_2, acc_2 = dx.prediction_xgb(xgb_2, x_train_balanced[features_2], y_train_balanced)\n",
    "y_val_pred_2, acc_val_2 = dx.prediction_xgb(xgb_2, x_val[features_2], y_val)\n",
    "\n",
    "# cumulative gain = 97.5%\n",
    "xgb_3, size_3, runtime_3, features_3 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .975, random_state=RANDOM_SEED)\n",
    "y_train_pred_3, acc_3 = dx.prediction_xgb(xgb_3, x_train_balanced[features_3], y_train_balanced)\n",
    "y_val_pred_3, acc_val_3 = dx.prediction_xgb(xgb_3, x_val[features_3], y_val)\n",
    "\n",
    "# cumulative gain = 99%\n",
    "xgb_4, size_4, runtime_4, features_4 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .99, random_state=RANDOM_SEED)\n",
    "y_train_pred_4, acc_4 = dx.prediction_xgb(xgb_4, x_train_balanced[features_4], y_train_balanced)\n",
    "y_val_pred_4, acc_val_4 = dx.prediction_xgb(xgb_4, x_val[features_4], y_val)\n",
    "\n",
    "xgb_iterations = [\"baseline\", \"cumulative gain = 80%\", \"cumulative gain = 90%\",\n",
    "                  \"cumulative gain = 95%\", \"cumulative gain = 97.5%\",  \"cumulative gain = 99%\"]\n",
    "xgb_train_acc = [acc_baseline, acc_0, acc_1, acc_2, acc_3, acc_4]\n",
    "xgb_val_acc = [acc_val_baseline, acc_val_0, acc_val_1, acc_val_2, acc_val_3, acc_val_4]\n",
    "xgb_n_feat = [23, len(features_0), len(features_1), len(features_2), len(features_3), len(features_4)]\n",
    "\n",
    "xgb_results = []\n",
    "for i in range(6):\n",
    "    xgb_results.extend([{\"iteration\": xgb_iterations[i],\n",
    "                         \"training accuracy\": format(xgb_train_acc[i],\".2%\"),\n",
    "                         \"validation accuracy\": format(xgb_val_acc[i],\".2%\"),\n",
    "                         \"number of features\": xgb_n_feat[i],}])\n",
    "\n",
    "display(pd.DataFrame(xgb_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e785a-e76f-42ae-a61f-fd23a88ca906",
   "metadata": {},
   "source": [
    "Now, this is the trickiest part. Unlike with `RANDOM_SEED=42`, here there's clear inverse relationship between size and accuracy. The most accurate model is the one with the most features, while the least accurate is the one with less than half of the features of the original model. For that reason, I'll be picking both extremes to compare against SPLIT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8643252-cdfb-437e-aae2-ed9e703ffd68",
   "metadata": {},
   "source": [
    "## 9 - Run SPLIT (lambda = 0.007) with the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a9669b-887a-4cb5-bf46-b50eca0b211a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>training runtime (s)</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "      <th>testing accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost (9 features)</td>\n",
       "      <td>100 trees, 758 leaves</td>\n",
       "      <td>0.14</td>\n",
       "      <td>91.43%</td>\n",
       "      <td>92.72%</td>\n",
       "      <td>92.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPLIT (9 features)</td>\n",
       "      <td>6 leaves</td>\n",
       "      <td>4.05</td>\n",
       "      <td>88.12%</td>\n",
       "      <td>89.06%</td>\n",
       "      <td>88.80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost (19 features)</td>\n",
       "      <td>100 trees, 758 leaves</td>\n",
       "      <td>0.18</td>\n",
       "      <td>92.49%</td>\n",
       "      <td>93.92%</td>\n",
       "      <td>93.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPLIT (19 features)</td>\n",
       "      <td>6 leaves</td>\n",
       "      <td>5.06</td>\n",
       "      <td>88.12%</td>\n",
       "      <td>89.06%</td>\n",
       "      <td>88.80%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model                   size training runtime (s)  \\\n",
       "0   XGBoost (9 features)  100 trees, 758 leaves                 0.14   \n",
       "1     SPLIT (9 features)               6 leaves                 4.05   \n",
       "2  XGBoost (19 features)  100 trees, 758 leaves                 0.18   \n",
       "3    SPLIT (19 features)               6 leaves                 5.06   \n",
       "\n",
       "  training accuracy validation accuracy testing accuracy  \n",
       "0            91.43%              92.72%           92.49%  \n",
       "1            88.12%              89.06%           88.80%  \n",
       "2            92.49%              93.92%           93.38%  \n",
       "3            88.12%              89.06%           88.80%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9 features, 80% cumulative gain\n",
    "model_6, tree_6, model_data_6 = dx.train_split(x_train_balanced[features_0], y_train_balanced, 2, 5, 0.007)\n",
    "train_prediction_6 = dx.prediction_split(model_6, x_train_balanced[features_0], y_train_balanced)\n",
    "val_prediction_6 = dx.prediction_split(model_6, x_val[features_0], y_val)\n",
    "test_prediction_6 = dx.prediction_split(model_6, x_test[features_0], y_test)\n",
    "\n",
    "y_test_pred_0, acc_pred_0 = dx.prediction_xgb(xgb_0, x_test[features_0], y_test)\n",
    "\n",
    "# 19 features, 99% cumulative gain\n",
    "model_7, tree_7, model_data_7 = dx.train_split(x_train_balanced[features_4], y_train_balanced, 2, 5, 0.007)\n",
    "train_prediction_7 = dx.prediction_split(model_7, x_train_balanced[features_4], y_train_balanced)\n",
    "val_prediction_7 = dx.prediction_split(model_7, x_val[features_4], y_val)\n",
    "test_prediction_7 = dx.prediction_split(model_7, x_test[features_4], y_test)\n",
    "\n",
    "y_test_pred_4, acc_pred_4 = dx.prediction_xgb(xgb_4, x_test[features_4], y_test)\n",
    "\n",
    "split_xgb_results = []\n",
    "split_xgb_results.extend([{\"model\": \"XGBoost (9 features)\",\n",
    "                           \"size\": str(size_0[\"trees\"]) + \" trees, \" + str(size_0[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(runtime_0, \".2f\"),\n",
    "                           \"training accuracy\": format(acc_0, \".2%\"),                           \n",
    "                           \"validation accuracy\": format(acc_val_0, \".2%\"),\n",
    "                           \"testing accuracy\": format(acc_pred_0, \".2%\"),},\n",
    "                          {\"model\": \"SPLIT (9 features)\",\n",
    "                           \"size\": str(model_data_6[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_6[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_6[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_6[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_6[1], \".2%\"),},\n",
    "                         {\"model\": \"XGBoost (19 features)\",\n",
    "                           \"size\": str(size_4[\"trees\"]) + \" trees, \" + str(size_4[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(runtime_4, \".2f\"),\n",
    "                           \"training accuracy\": format(acc_4, \".2%\"),                           \n",
    "                           \"validation accuracy\": format(acc_val_4, \".2%\"),\n",
    "                           \"testing accuracy\": format(acc_pred_4, \".2%\"),},\n",
    "                          {\"model\": \"SPLIT (19 features)\",\n",
    "                           \"size\": str(model_data_7[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_7[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_7[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_7[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_7[1], \".2%\"),},])\n",
    "\n",
    "display(pd.DataFrame(split_xgb_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4b6ce-7ff5-442b-9b7c-8bbbe9f29ce9",
   "metadata": {},
   "source": [
    "Now, this is interesting. While the feature selection affected XGBoost's outcome, it didn't for SPLIT. Accuracy stayed exactly the same with the smaller model, so I'll be proceeding with it.\n",
    "\n",
    "**Features selected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5afc0d11-1e07-47d3-aba1-463b8ad74dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Online_boarding', 'Type_of_Travel_Personal Travel', 'Class_Eco', 'Inflight_wifi_service', 'On_board_service', 'Customer_Type_disloyal Customer', 'Flight_Distance', 'Inflight_entertainment', 'Leg_room_service']\n"
     ]
    }
   ],
   "source": [
    "print(features_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e1914-af73-402a-ba24-232fa612b89c",
   "metadata": {},
   "source": [
    "## 9.1 - Run SPLIT (lookahead depth = 2-4, max depth = 6, lambda = 0.005) with selected features\n",
    "\n",
    "Here I'm comparing both the baselines for SPLIT and XGBoost with the same models after feature selection, and testing a different set of parameters for SPLIT. I decided to extend SPLIT's maximum depth to 6, again try different values of the lookahead depth, and a smaller lambda to maximize interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c238893d-bfde-405d-83fe-ca6d5df3b940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>training runtime (s)</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "      <th>testing accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost (9 features)</td>\n",
       "      <td>100 trees, 758 leaves</td>\n",
       "      <td>0.14</td>\n",
       "      <td>91.43%</td>\n",
       "      <td>92.72%</td>\n",
       "      <td>92.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPLIT (lookahead depth=2, max depth=5, lambda=0.007)</td>\n",
       "      <td>6 leaves</td>\n",
       "      <td>4.05</td>\n",
       "      <td>88.12%</td>\n",
       "      <td>89.06%</td>\n",
       "      <td>88.80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPLIT (lookahead depth=2, max depth=6, lambda=0.005)</td>\n",
       "      <td>8 leaves</td>\n",
       "      <td>4.89</td>\n",
       "      <td>90.36%</td>\n",
       "      <td>92.27%</td>\n",
       "      <td>91.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPLIT (lookahead depth=3, max depth=6, lambda=0.005)</td>\n",
       "      <td>8 leaves</td>\n",
       "      <td>5.13</td>\n",
       "      <td>89.83%</td>\n",
       "      <td>90.40%</td>\n",
       "      <td>90.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPLIT (lookahead depth=4, max depth=6, lambda=0.005)</td>\n",
       "      <td>8 leaves</td>\n",
       "      <td>11.51</td>\n",
       "      <td>89.67%</td>\n",
       "      <td>90.40%</td>\n",
       "      <td>90.37%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  model  \\\n",
       "0                                  XGBoost (9 features)   \n",
       "1  SPLIT (lookahead depth=2, max depth=5, lambda=0.007)   \n",
       "2  SPLIT (lookahead depth=2, max depth=6, lambda=0.005)   \n",
       "3  SPLIT (lookahead depth=3, max depth=6, lambda=0.005)   \n",
       "4  SPLIT (lookahead depth=4, max depth=6, lambda=0.005)   \n",
       "\n",
       "                    size training runtime (s) training accuracy  \\\n",
       "0  100 trees, 758 leaves                 0.14            91.43%   \n",
       "1               6 leaves                 4.05            88.12%   \n",
       "2               8 leaves                 4.89            90.36%   \n",
       "3               8 leaves                 5.13            89.83%   \n",
       "4               8 leaves                11.51            89.67%   \n",
       "\n",
       "  validation accuracy testing accuracy  \n",
       "0              92.72%           92.49%  \n",
       "1              89.06%           88.80%  \n",
       "2              92.27%           91.73%  \n",
       "3              90.40%           90.35%  \n",
       "4              90.40%           90.37%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_xgb_results.pop()\n",
    "split_xgb_results.pop()\n",
    "split_xgb_results.pop()\n",
    "\n",
    "# Lookahead depth = 2, max depth = 6, lambda = 0.005\n",
    "model_8, tree_8, model_data_8 = dx.train_split(x_train_balanced[features_0], y_train_balanced, 2, 6, 0.005)\n",
    "train_prediction_8 = dx.prediction_split(model_8, x_train_balanced[features_0], y_train_balanced)\n",
    "val_prediction_8 = dx.prediction_split(model_8, x_val[features_0], y_val)\n",
    "test_prediction_8 = dx.prediction_split(model_8, x_test[features_0], y_test)\n",
    "\n",
    "# Lookahead depth = 3, max depth = 6, lambda = 0.005\n",
    "model_9, tree_9, model_data_9 = dx.train_split(x_train_balanced[features_0], y_train_balanced, 3, 6, 0.005)\n",
    "train_prediction_9 = dx.prediction_split(model_9, x_train_balanced[features_0], y_train_balanced)\n",
    "val_prediction_9 = dx.prediction_split(model_9, x_val[features_0], y_val)\n",
    "test_prediction_9 = dx.prediction_split(model_9, x_test[features_0], y_test)\n",
    "\n",
    "# Lookahead depth = 4, max depth = 6, lambda = 0.005\n",
    "model_10, tree_10, model_data_10 = dx.train_split(x_train_balanced[features_0], y_train_balanced, 4, 6, 0.005)\n",
    "train_prediction_10 = dx.prediction_split(model_10, x_train_balanced[features_0], y_train_balanced)\n",
    "val_prediction_10 = dx.prediction_split(model_10, x_val[features_0], y_val)\n",
    "test_prediction_10 = dx.prediction_split(model_10, x_test[features_0], y_test)\n",
    "\n",
    "split_xgb_results.extend([{\"model\": \"SPLIT (lookahead depth=2, max depth=5, lambda=0.007)\",\n",
    "                           \"size\": str(model_data_6[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_6[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_6[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_6[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_6[1], \".2%\"),},\n",
    "                          {\"model\": \"SPLIT (lookahead depth=2, max depth=6, lambda=0.005)\",\n",
    "                           \"size\": str(model_data_8[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_8[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_8[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_8[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_8[1], \".2%\"),},\n",
    "                            {\"model\": \"SPLIT (lookahead depth=3, max depth=6, lambda=0.005)\",\n",
    "                           \"size\": str(model_data_9[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_9[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_9[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_9[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_9[1], \".2%\"),},\n",
    "                            {\"model\": \"SPLIT (lookahead depth=4, max depth=6, lambda=0.005)\",\n",
    "                           \"size\": str(model_data_10[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_10[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_10[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_10[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_10[1], \".2%\"),},])\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "display(pd.DataFrame(split_xgb_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc26dd1-a434-47b6-ae2f-1108df56ee11",
   "metadata": {},
   "source": [
    "Like with `RANDOM_SEED=42` the choice is **model[2]**, the difference from the baseline being the extra maximum depth, with minimal increase in runtime and maintaining a reasonable level of interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c1b4b-ffb5-41e3-bfae-11e44443c816",
   "metadata": {},
   "source": [
    "**Model[2] tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad4d9d6-9ecc-4bb5-91da-31736009928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ feature: 4 [ left child: { prediction: 1, loss: 0.002058142563328147 }, right child: { feature: 2 [ left child: { feature: 5 [ left child: { feature: 8 [ left child: { feature: 1 [ left child: { prediction: 0, loss: 0.033169761300086975 }, right child: { prediction: 1, loss: 0.0007312324596568942 }] }, right child: { feature: 7 [ left child: { prediction: 1, loss: 0.004202384036034346 }, right child: { prediction: 0, loss: 0.002792779356241226 }] }] }, right child: { prediction: 1, loss: 0.037398576736450195 }] }, right child: { feature: 6 [ left child: { prediction: 0, loss: 0.02133789099752903 }, right child: { prediction: 1, loss: 0.0 }] }] }] }\n"
     ]
    }
   ],
   "source": [
    "print(tree_8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
