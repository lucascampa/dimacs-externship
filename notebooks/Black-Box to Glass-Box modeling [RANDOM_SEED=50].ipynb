{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2024a6ab-71ac-4e03-9e91-7f9e2de5056a",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Get stats about missing data points\n",
    "2. Clean missing data points\n",
    "3. Encode and binarize the labels\n",
    "4. Split the test dataset between validation and test\n",
    "5. Get the balance stats for each split\n",
    "6. Run SMOTE\n",
    "7. Run SPLIT -> depth = 2, max_depth = 5, lambda = 0.005, 0.006, 0.007, 0.008, 0.009, 0.01\n",
    "8. Run XGBoost to select features -> baseline iteration, then cumulative gain = 80%, 90%, 95% , 97.5%, 99%\n",
    "9. Run SPLIT with the selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59ce73-3e0e-4ce0-8e70-4978603afef2",
   "metadata": {},
   "source": [
    "## 1 and 2 - Get stats about missing data points, clean missing data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d9bece0-d5de-4f44-b554-b2b09f30e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset saved to /mnt/c/Users/Lucas/Documents/Externship/SPLIT-ICML/airline-passenger-satisfaction/train_clean.csv\n",
      "Clean dataset saved to /mnt/c/Users/Lucas/Documents/Externship/SPLIT-ICML/airline-passenger-satisfaction/test_clean.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>size</th>\n",
       "      <th>missing data points</th>\n",
       "      <th>% missing data points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>103904</td>\n",
       "      <td>310</td>\n",
       "      <td>0.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>25976</td>\n",
       "      <td>83</td>\n",
       "      <td>0.32%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset    size  missing data points % missing data points\n",
       "0   train  103904                  310                 0.30%\n",
       "1   train   25976                   83                 0.32%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dimex as dx\n",
    "\n",
    "RANDOM_SEED = 50\n",
    "\n",
    "train_filename = 'airline-passenger-satisfaction/train.csv'\n",
    "test_filename = 'airline-passenger-satisfaction/test.csv'\n",
    "\n",
    "train_dataset = pd.read_csv(train_filename, index_col=0)\n",
    "test_dataset = pd.read_csv(test_filename, index_col=0)\n",
    "\n",
    "train_clean, train_missing_stats, train_clean_filename = dx.clean_missing(train_filename)\n",
    "test_clean, test_missing_stats, test_clean_filename = dx.clean_missing(test_filename)\n",
    "\n",
    "train_missing_stats = list(train_missing_stats.items())\n",
    "test_missing_stats = list(test_missing_stats.items())\n",
    "\n",
    "missing_tbl = []\n",
    "missing_tbl.extend([{\n",
    "    \"dataset\": \"train\",\n",
    "    \"size\": len(train_dataset),\n",
    "    train_missing_stats[0][0]: train_missing_stats[0][1],\n",
    "    train_missing_stats[1][0]: format(train_missing_stats[1][1],\".2%\"),\n",
    "}, {\n",
    "    \"dataset\": \"train\",\n",
    "    \"size\": len(test_dataset),\n",
    "    test_missing_stats[0][0]: test_missing_stats[0][1],\n",
    "    test_missing_stats[1][0]: format(test_missing_stats[1][1],\".2%\"),\n",
    "},])\n",
    "\n",
    "display(pd.DataFrame(missing_tbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798d66d-1471-43b5-8358-c4ae9c1c5d13",
   "metadata": {},
   "source": [
    "## 3, 4, and 5 - Encode the features, binarize the labels, split the dataset, get the balance stats for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c1ebc03-2657-4f1a-8a0b-d0d4d403f83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded dataset saved to /mnt/c/Users/Lucas/Documents/Externship/SPLIT-ICML/airline-passenger-satisfaction/train_clean_encoded.csv\n",
      "Encoded dataset saved to /mnt/c/Users/Lucas/Documents/Externship/SPLIT-ICML/airline-passenger-satisfaction/test_clean_encoded.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>43.34%</td>\n",
       "      <td>56.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation</td>\n",
       "      <td>43.89%</td>\n",
       "      <td>56.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>43.89%</td>\n",
       "      <td>56.11%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset       1       0\n",
       "0       train  43.34%  56.66%\n",
       "1  validation  43.89%  56.11%\n",
       "2        test  43.89%  56.11%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_encoded, train_encoded_filename = dx.binarize_encode(train_clean_filename, \"satisfied\", \"neutral or dissatisfied\")\n",
    "test_encoded, test_encoded_filename = dx.binarize_encode(test_clean_filename, \"satisfied\", \"neutral or dissatisfied\")\n",
    "\n",
    "x_val, x_test, y_val, y_test = dx.split_dataset(test_encoded, test_size=2/3, random_state=RANDOM_SEED)\n",
    "\n",
    "labels = train_encoded.columns[-1]\n",
    "train_balance = dx.balance_stats(train_encoded[labels])\n",
    "val_balance = dx.balance_stats(y_val)\n",
    "test_balance = dx.balance_stats(y_test)\n",
    "\n",
    "balance_stats = []\n",
    "balance_stats.extend([{\"dataset\": \"train\",\n",
    "                       \"1\": format(train_balance[\"1\"], \".2%\"),\n",
    "                       \"0\": format(train_balance[\"0\"], \".2%\"),},\n",
    "                      {\"dataset\": \"validation\",\n",
    "                       \"1\": format(val_balance[\"1\"], \".2%\"),\n",
    "                       \"0\": format(val_balance[\"0\"], \".2%\"),},\n",
    "                      {\"dataset\": \"test\",\n",
    "                       \"1\": format(test_balance[\"1\"], \".2%\"),\n",
    "                       \"0\": format(test_balance[\"0\"], \".2%\"),}])\n",
    "\n",
    "display(pd.DataFrame(balance_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3cf716-3e42-47ad-b018-ed8f7c768894",
   "metadata": {},
   "source": [
    "## 6 - Balance with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b0985aa-937b-49b9-8836-02e9ad384b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset saved to /mnt/c/Users/Lucas/Documents/Externship/SPLIT-ICML/airline-passenger-satisfaction/train_clean_encoded_balanced.csv\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = train_encoded.drop(columns=[labels]), train_encoded[labels]\n",
    "x_train_balanced, y_train_balanced = dx.smote(x_train, y_train, train_encoded_filename, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e16d33-3767-47a1-8e86-14d50f43deed",
   "metadata": {},
   "source": [
    "## 7 - Run SPLIT -> Depth = 2, max depth = 5, lambda = 0.005-0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cea07c1-e740-416a-8506-0fe42e1a9deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>leaves</th>\n",
       "      <th>training runtime (s)</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>6.78</td>\n",
       "      <td>87.96%</td>\n",
       "      <td>89.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006</td>\n",
       "      <td>6</td>\n",
       "      <td>6.45</td>\n",
       "      <td>87.96%</td>\n",
       "      <td>89.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007</td>\n",
       "      <td>6</td>\n",
       "      <td>6.54</td>\n",
       "      <td>87.96%</td>\n",
       "      <td>89.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008</td>\n",
       "      <td>5</td>\n",
       "      <td>6.43</td>\n",
       "      <td>87.10%</td>\n",
       "      <td>88.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009</td>\n",
       "      <td>5</td>\n",
       "      <td>6.33</td>\n",
       "      <td>87.10%</td>\n",
       "      <td>88.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>5</td>\n",
       "      <td>6.49</td>\n",
       "      <td>87.10%</td>\n",
       "      <td>88.38%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lambda  leaves training runtime (s) training accuracy validation accuracy\n",
       "0   0.005       6                 6.78            87.96%              89.06%\n",
       "1   0.006       6                 6.45            87.96%              89.06%\n",
       "2   0.007       6                 6.54            87.96%              89.06%\n",
       "3   0.008       5                 6.43            87.10%              88.38%\n",
       "4   0.009       5                 6.33            87.10%              88.38%\n",
       "5   0.010       5                 6.49            87.10%              88.38%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iteration 0 -> Lambda = 0.005\n",
    "model_0, tree_0, model_data_0 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.005)\n",
    "train_prediction_0 = dx.prediction_split(model_0, x_train_balanced, y_train_balanced)\n",
    "val_prediction_0 = dx.prediction_split(model_0, x_val, y_val)\n",
    "\n",
    "# Iteration 1 -> Lambda = 0.006\n",
    "model_1, tree_1, model_data_1 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.006)\n",
    "train_prediction_1 = dx.prediction_split(model_1, x_train_balanced, y_train_balanced)\n",
    "val_prediction_1 = dx.prediction_split(model_1, x_val, y_val)\n",
    "\n",
    "# Iteration 2 -> Lambda = 0.007\n",
    "model_2, tree_2, model_data_2 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.007)\n",
    "train_prediction_2 = dx.prediction_split(model_2, x_train_balanced, y_train_balanced)\n",
    "val_prediction_2 = dx.prediction_split(model_2, x_val, y_val)\n",
    "\n",
    "# Iteration 3 -> Lambda = 0.008\n",
    "model_3, tree_3, model_data_3 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.008)\n",
    "train_prediction_3 = dx.prediction_split(model_3, x_train_balanced, y_train_balanced)\n",
    "val_prediction_3 = dx.prediction_split(model_3, x_val, y_val)\n",
    "\n",
    "# Iteration 4 -> Lambda = 0.009\n",
    "model_4, tree_4, model_data_4 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.009)\n",
    "train_prediction_4 = dx.prediction_split(model_4, x_train_balanced, y_train_balanced)\n",
    "val_prediction_4 = dx.prediction_split(model_4, x_val, y_val)\n",
    "\n",
    "# Iteration 5 -> Lambda = 0.01\n",
    "model_5, tree_5, model_data_5 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.01)\n",
    "train_prediction_5 = dx.prediction_split(model_5, x_train_balanced, y_train_balanced)\n",
    "val_prediction_5 = dx.prediction_split(model_5, x_val, y_val)\n",
    "\n",
    "models_data = [model_data_0, model_data_1, model_data_2, model_data_3, model_data_4, model_data_5]\n",
    "train_predictions = [train_prediction_0, train_prediction_1, train_prediction_2, train_prediction_3, train_prediction_4, train_prediction_5]\n",
    "val_predictions = [val_prediction_0, val_prediction_1, val_prediction_2, val_prediction_3, val_prediction_4, val_prediction_5]\n",
    "\n",
    "split_results = []\n",
    "\n",
    "for i in range(6):\n",
    "    split_results.extend([{\"lambda\": models_data[i][\"lambda\"],\n",
    "                           \"leaves\": models_data[i][\"leaves\"],\n",
    "                           \"training runtime (s)\": format(models_data[i][\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_predictions[i][1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_predictions[i][1], \".2%\"),}])\n",
    "\n",
    "display(pd.DataFrame(split_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c08f194-93fd-45ce-ae18-0f425cc96029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda 0.005 tree: { feature: 0 [ left child: { prediction: 1, loss: 0.002084418898448348 }, right child: { feature: 7 [ left child: { feature: 1 [ left child: { feature: 3 [ left child: { prediction: 0, loss: 0.0398745983839035 }, right child: { prediction: 1, loss: 0.0251770056784153 }] }, right child: { prediction: 1, loss: 0.03738243877887726 }] }, right child: { feature: 2 [ left child: { prediction: 0, loss: 0.022006763145327568 }, right child: { prediction: 1, loss: 0.0 }] }] }] } \n",
      "\n",
      "lambda 0.006 tree: { feature: 0 [ left child: { prediction: 1, loss: 0.002084418898448348 }, right child: { feature: 7 [ left child: { feature: 1 [ left child: { feature: 3 [ left child: { prediction: 0, loss: 0.0398745983839035 }, right child: { prediction: 1, loss: 0.0251770056784153 }] }, right child: { prediction: 1, loss: 0.03738243877887726 }] }, right child: { feature: 2 [ left child: { prediction: 0, loss: 0.022006763145327568 }, right child: { prediction: 1, loss: 0.0 }] }] }] } \n",
      "\n",
      "lambda 0.007 tree: { feature: 0 [ left child: { prediction: 1, loss: 0.002084418898448348 }, right child: { feature: 7 [ left child: { feature: 1 [ left child: { feature: 3 [ left child: { prediction: 0, loss: 0.0398745983839035 }, right child: { prediction: 1, loss: 0.0251770056784153 }] }, right child: { prediction: 1, loss: 0.03738243877887726 }] }, right child: { feature: 2 [ left child: { prediction: 0, loss: 0.022006763145327568 }, right child: { prediction: 1, loss: 0.0 }] }] }] }\n"
     ]
    }
   ],
   "source": [
    "print(\"lambda\",models_data[0][\"lambda\"], \"tree:\", tree_0, \"\\n\")\n",
    "print(\"lambda\",models_data[1][\"lambda\"], \"tree:\", tree_1, \"\\n\")\n",
    "print(\"lambda\",models_data[2][\"lambda\"], \"tree:\", tree_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f27728-ebb6-46e7-b018-cb5638e5fc3d",
   "metadata": {},
   "source": [
    "Despite the different lambdas, the 3 trees are identical. Same number of leaves, same loss, same accuracy. I'm picking lambda = 0.007 because it keeps accuracy and tree size the same while giving the most regularization cushion against small shifts in data and pipeline or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb15b009-3d81-44d3-8962-0ef10b6642e2",
   "metadata": {},
   "source": [
    "## 8 - Run XGBoost -> baseline iteration, cumulative gain = 80%-99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87ca9539-4870-448d-907e-bbc407242ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>92.46%</td>\n",
       "      <td>94.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cumulative gain = 80%</td>\n",
       "      <td>91.72%</td>\n",
       "      <td>93.07%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cumulative gain = 90%</td>\n",
       "      <td>92.19%</td>\n",
       "      <td>93.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cumulative gain = 95%</td>\n",
       "      <td>92.32%</td>\n",
       "      <td>93.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cumulative gain = 97.5%</td>\n",
       "      <td>92.27%</td>\n",
       "      <td>93.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cumulative gain = 99%</td>\n",
       "      <td>92.33%</td>\n",
       "      <td>93.99%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 iteration training accuracy validation accuracy\n",
       "0                 baseline            92.46%              94.03%\n",
       "1    cumulative gain = 80%            91.72%              93.07%\n",
       "2    cumulative gain = 90%            92.19%              93.62%\n",
       "3    cumulative gain = 95%            92.32%              93.82%\n",
       "4  cumulative gain = 97.5%            92.27%              93.74%\n",
       "5    cumulative gain = 99%            92.33%              93.99%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# baseline\n",
    "xgb_baseline, size_baseline, runtime_baseline = dx.train_xgb(x_train_balanced, y_train_balanced, random_state=RANDOM_SEED)\n",
    "y_train_pred_baseline, acc_baseline = dx.prediction_xgb(xgb_baseline, x_train_balanced, y_train_balanced)\n",
    "y_val_pred_baseline, acc_val_baseline = dx.prediction_xgb(xgb_baseline, x_val, y_val)\n",
    "\n",
    "gain_sorted, total_gain = dx.sort_by_gain(xgb_baseline)\n",
    "\n",
    "# cumulative gain = 80%\n",
    "xgb_0, size_0, runtime_0, features_0 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .8, random_state=RANDOM_SEED)\n",
    "y_train_pred_0, acc_0 = dx.prediction_xgb(xgb_0, x_train_balanced[features_0], y_train_balanced)\n",
    "y_val_pred_0, acc_val_0 = dx.prediction_xgb(xgb_0, x_val[features_0], y_val)\n",
    "\n",
    "# cumulative gain = 90%\n",
    "xgb_1, size_1, runtime_1, features_1 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .9, random_state=RANDOM_SEED)\n",
    "y_train_pred_1, acc_1 = dx.prediction_xgb(xgb_1, x_train_balanced[features_1], y_train_balanced)\n",
    "y_val_pred_1, acc_val_1 = dx.prediction_xgb(xgb_1, x_val[features_1], y_val)\n",
    "\n",
    "# cumulative gain = 95%\n",
    "xgb_2, size_2, runtime_2, features_2 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .95, random_state=RANDOM_SEED)\n",
    "y_train_pred_2, acc_2 = dx.prediction_xgb(xgb_2, x_train_balanced[features_2], y_train_balanced)\n",
    "y_val_pred_2, acc_val_2 = dx.prediction_xgb(xgb_2, x_val[features_2], y_val)\n",
    "\n",
    "# cumulative gain = 97.5%\n",
    "xgb_3, size_3, runtime_3, features_3 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .975, random_state=RANDOM_SEED)\n",
    "y_train_pred_3, acc_3 = dx.prediction_xgb(xgb_3, x_train_balanced[features_3], y_train_balanced)\n",
    "y_val_pred_3, acc_val_3 = dx.prediction_xgb(xgb_3, x_val[features_3], y_val)\n",
    "\n",
    "# cumulative gain = 99%\n",
    "xgb_4, size_4, runtime_4, features_4 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .99, random_state=RANDOM_SEED)\n",
    "y_train_pred_4, acc_4 = dx.prediction_xgb(xgb_4, x_train_balanced[features_4], y_train_balanced)\n",
    "y_val_pred_4, acc_val_4 = dx.prediction_xgb(xgb_4, x_val[features_4], y_val)\n",
    "\n",
    "xgb_iterations = [\"baseline\", \"cumulative gain = 80%\", \"cumulative gain = 90%\",\n",
    "                  \"cumulative gain = 95%\", \"cumulative gain = 97.5%\",  \"cumulative gain = 99%\"]\n",
    "xgb_train_acc = [acc_baseline, acc_0, acc_1, acc_2, acc_3, acc_4]\n",
    "xgb_val_acc = [acc_val_baseline, acc_val_0, acc_val_1, acc_val_2, acc_val_3, acc_val_4]\n",
    "\n",
    "xgb_results = []\n",
    "for i in range(6):\n",
    "    xgb_results.extend([{\"iteration\": xgb_iterations[i],\n",
    "                         \"training accuracy\": format(xgb_train_acc[i],\".2%\"),\n",
    "                         \"validation accuracy\": format(xgb_val_acc[i],\".2%\"),}])\n",
    "\n",
    "display(pd.DataFrame(xgb_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e785a-e76f-42ae-a61f-fd23a88ca906",
   "metadata": {},
   "source": [
    "Both the baseline and the cumulative gain = 99% scenarios yielded the same accuracy. I'll pick the **99% cumulative gain**. Why? It's a simpler model, even if slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8643252-cdfb-437e-aae2-ed9e703ffd68",
   "metadata": {},
   "source": [
    "## 9 - Run SPLIT (lambda = 0.007) with the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3a9669b-887a-4cb5-bf46-b50eca0b211a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>training runtime (s)</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "      <th>testing accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>100 trees, 758 leaves</td>\n",
       "      <td>0.25</td>\n",
       "      <td>92.33%</td>\n",
       "      <td>93.99%</td>\n",
       "      <td>93.44%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPLIT</td>\n",
       "      <td>6 leaves</td>\n",
       "      <td>6.59</td>\n",
       "      <td>87.96%</td>\n",
       "      <td>89.06%</td>\n",
       "      <td>88.80%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                   size training runtime (s) training accuracy  \\\n",
       "0  XGBoost  100 trees, 758 leaves                 0.25            92.33%   \n",
       "1    SPLIT               6 leaves                 6.59            87.96%   \n",
       "\n",
       "  validation accuracy testing accuracy  \n",
       "0              93.99%           93.44%  \n",
       "1              89.06%           88.80%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_6, tree_6, model_data_6 = dx.train_split(x_train_balanced[features_4], y_train_balanced, 2, 5, 0.007)\n",
    "train_prediction_6 = dx.prediction_split(model_6, x_train_balanced[features_4], y_train_balanced)\n",
    "val_prediction_6 = dx.prediction_split(model_6, x_val[features_4], y_val)\n",
    "test_prediction_6 = dx.prediction_split(model_6, x_test[features_4], y_test)\n",
    "\n",
    "y_test_pred_4, acc_pred_4 = dx.prediction_xgb(xgb_4, x_test[features_4], y_test)\n",
    "\n",
    "split_xgb_results = []\n",
    "split_xgb_results.extend([{\"model\": \"XGBoost\",\n",
    "                           \"size\": str(size_4[\"trees\"]) + \" trees, \" + str(size_4[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(runtime_4, \".2f\"),\n",
    "                           \"training accuracy\": format(acc_4, \".2%\"),                           \n",
    "                           \"validation accuracy\": format(acc_val_4, \".2%\"),\n",
    "                           \"testing accuracy\": format(acc_pred_4, \".2%\"),},\n",
    "                          {\"model\": \"SPLIT\",\n",
    "                           \"size\": str(model_data_6[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_6[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_6[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_6[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_6[1], \".2%\"),},])\n",
    "\n",
    "display(pd.DataFrame(split_xgb_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4b6ce-7ff5-442b-9b7c-8bbbe9f29ce9",
   "metadata": {},
   "source": [
    "The accuracy didn't improve at all, nor did sparsity. What I'm doing now is applying a different set of parameters I found through tinkering with SPLIT in another notebook (no need to repeat the process here. It was the same trial-and-error process you saw on step 7, but also messing with depth and max depth). I'm using that because it yielded a higher accuracy. But it was with `RANDOM_SEED=42`. We'll see if accuracy remains the same with this seed. If it differs too much, it's a sign the model is not stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e1914-af73-402a-ba24-232fa612b89c",
   "metadata": {},
   "source": [
    "## 9.1 - Run SPLIT (depth = 5, max depth = 6, lambda = 0.005) with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c238893d-bfde-405d-83fe-ca6d5df3b940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>training runtime (s)</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "      <th>testing accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>100 trees, 758 leaves</td>\n",
       "      <td>0.25</td>\n",
       "      <td>92.33%</td>\n",
       "      <td>93.99%</td>\n",
       "      <td>93.44%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPLIT (depth=2, max depth=5, lambda=0.007)</td>\n",
       "      <td>6 leaves</td>\n",
       "      <td>6.59</td>\n",
       "      <td>87.96%</td>\n",
       "      <td>89.06%</td>\n",
       "      <td>88.80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPLIT (depth=5, max depth=6, lambda=0.005)</td>\n",
       "      <td>6 leaves</td>\n",
       "      <td>13.46</td>\n",
       "      <td>87.96%</td>\n",
       "      <td>89.06%</td>\n",
       "      <td>88.80%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        model                   size  \\\n",
       "0                                     XGBoost  100 trees, 758 leaves   \n",
       "1  SPLIT (depth=2, max depth=5, lambda=0.007)               6 leaves   \n",
       "2  SPLIT (depth=5, max depth=6, lambda=0.005)               6 leaves   \n",
       "\n",
       "  training runtime (s) training accuracy validation accuracy testing accuracy  \n",
       "0                 0.25            92.33%              93.99%           93.44%  \n",
       "1                 6.59            87.96%              89.06%           88.80%  \n",
       "2                13.46            87.96%              89.06%           88.80%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_xgb_results.pop()\n",
    "\n",
    "model_7, tree_7, model_data_7 = dx.train_split(x_train_balanced[features_4], y_train_balanced, 5, 6, 0.005)\n",
    "train_prediction_7 = dx.prediction_split(model_7, x_train_balanced[features_4], y_train_balanced)\n",
    "val_prediction_7 = dx.prediction_split(model_7, x_val[features_4], y_val)\n",
    "test_prediction_7 = dx.prediction_split(model_7, x_test[features_4], y_test)\n",
    "\n",
    "split_xgb_results.extend([{\"model\": \"SPLIT (depth=2, max depth=5, lambda=0.007)\",\n",
    "                           \"size\": str(model_data_6[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_6[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_6[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_6[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_6[1], \".2%\"),},\n",
    "                          {\"model\": \"SPLIT (depth=5, max depth=6, lambda=0.005)\",\n",
    "                           \"size\": str(model_data_7[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_7[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_7[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_7[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_7[1], \".2%\"),},])\n",
    "\n",
    "display(pd.DataFrame(split_xgb_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc26dd1-a434-47b6-ae2f-1108df56ee11",
   "metadata": {},
   "source": [
    "The accuracy here fell sharply compared to the `RANDOM_SEED=42` model, suggesting that SPLIT with this set of parameters (depth=5, max depth=6, lambda=0.005) is not stable. So, I'll keep the SPLIT with depth 2, max depth 5, and lambda 0.007. Below, its tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fad4d9d6-9ecc-4bb5-91da-31736009928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ feature: 3 [ left child: { prediction: 1, loss: 0.002084418898448348 }, right child: { feature: 2 [ left child: { feature: 0 [ left child: { feature: 4 [ left child: { prediction: 0, loss: 0.0398745983839035 }, right child: { prediction: 1, loss: 0.008876677602529526 }] }, right child: { prediction: 1, loss: 0.05368276685476303 }] }, right child: { feature: 5 [ left child: { prediction: 0, loss: 0.022006763145327568 }, right child: { prediction: 1, loss: 0.0 }] }] }] }\n"
     ]
    }
   ],
   "source": [
    "print(tree_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a26a488-6891-4a44-87c4-e1315776165c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
