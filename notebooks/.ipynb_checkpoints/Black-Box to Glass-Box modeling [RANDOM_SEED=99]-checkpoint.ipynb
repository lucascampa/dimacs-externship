{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2024a6ab-71ac-4e03-9e91-7f9e2de5056a",
   "metadata": {},
   "source": [
    "# Steps\n",
    "See [Black-Box to Glass-Box modeling \\[RANDOM_SEED=42\\]](Black-Box%20to%20Glass-Box%20modeling%20%5BRANDOM_SEED%3D42%5D.ipynb) for steps 1 through 6\n",
    "\n",
    "7. Run SPLIT -> lookahead depth = 2, max_depth = 5, lambda = 0.005, 0.006, 0.007, 0.008, 0.009, 0.01\n",
    "8. Run XGBoost to select features -> baseline iteration, then cumulative gain = 80%, 90%, 95% , 97.5%, 99%\n",
    "9. Run SPLIT with the selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59ce73-3e0e-4ce0-8e70-4978603afef2",
   "metadata": {},
   "source": [
    "## 1 and 2 - Get stats about missing data points, clean missing data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9bece0-d5de-4f44-b554-b2b09f30e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset saved to /mnt/c/Users/Lucas/Documents/Externship/SPLIT-ICML/airline-passenger-satisfaction/train_clean.csv\n",
      "Clean dataset saved to /mnt/c/Users/Lucas/Documents/Externship/SPLIT-ICML/airline-passenger-satisfaction/test_clean.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>size</th>\n",
       "      <th>missing data points</th>\n",
       "      <th>% missing data points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>103904</td>\n",
       "      <td>310</td>\n",
       "      <td>0.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>25976</td>\n",
       "      <td>83</td>\n",
       "      <td>0.32%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset    size  missing data points % missing data points\n",
       "0   train  103904                  310                 0.30%\n",
       "1   train   25976                   83                 0.32%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dimex as dx\n",
    "\n",
    "RANDOM_SEED = 99\n",
    "\n",
    "train_filename = '../airline-passenger-satisfaction/train.csv'\n",
    "test_filename = '../airline-passenger-satisfaction/test.csv'\n",
    "\n",
    "train_dataset = pd.read_csv(train_filename, index_col=0)\n",
    "test_dataset = pd.read_csv(test_filename, index_col=0)\n",
    "\n",
    "train_clean, train_missing_stats, train_clean_filename = dx.clean_missing(train_filename)\n",
    "test_clean, test_missing_stats, test_clean_filename = dx.clean_missing(test_filename)\n",
    "\n",
    "train_missing_stats = list(train_missing_stats.items())\n",
    "test_missing_stats = list(test_missing_stats.items())\n",
    "\n",
    "missing_tbl = []\n",
    "missing_tbl.extend([{\n",
    "    \"dataset\": \"train\",\n",
    "    \"size\": len(train_dataset),\n",
    "    train_missing_stats[0][0]: train_missing_stats[0][1],\n",
    "    train_missing_stats[1][0]: format(train_missing_stats[1][1],\".2%\"),\n",
    "}, {\n",
    "    \"dataset\": \"train\",\n",
    "    \"size\": len(test_dataset),\n",
    "    test_missing_stats[0][0]: test_missing_stats[0][1],\n",
    "    test_missing_stats[1][0]: format(test_missing_stats[1][1],\".2%\"),\n",
    "},])\n",
    "\n",
    "display(pd.DataFrame(missing_tbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798d66d-1471-43b5-8358-c4ae9c1c5d13",
   "metadata": {},
   "source": [
    "## 3, 4, and 5 - Encode the features, binarize the labels, split the dataset, get the balance stats for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1ebc03-2657-4f1a-8a0b-d0d4d403f83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded dataset saved to /mnt/c/Users/Lucas/Documents/Externship/SPLIT-ICML/airline-passenger-satisfaction/train_clean_encoded.csv\n",
      "Encoded dataset saved to /mnt/c/Users/Lucas/Documents/Externship/SPLIT-ICML/airline-passenger-satisfaction/test_clean_encoded.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>43.34%</td>\n",
       "      <td>56.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation</td>\n",
       "      <td>43.89%</td>\n",
       "      <td>56.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>43.89%</td>\n",
       "      <td>56.11%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset       1       0\n",
       "0       train  43.34%  56.66%\n",
       "1  validation  43.89%  56.11%\n",
       "2        test  43.89%  56.11%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_encoded, train_encoded_filename = dx.binarize_encode(train_clean_filename, \"satisfied\", \"neutral or dissatisfied\")\n",
    "test_encoded, test_encoded_filename = dx.binarize_encode(test_clean_filename, \"satisfied\", \"neutral or dissatisfied\")\n",
    "\n",
    "x_val, x_test, y_val, y_test = dx.split_dataset(test_encoded, test_size=2/3, random_state=RANDOM_SEED)\n",
    "\n",
    "labels = train_encoded.columns[-1]\n",
    "train_balance = dx.balance_stats(train_encoded[labels])\n",
    "val_balance = dx.balance_stats(y_val)\n",
    "test_balance = dx.balance_stats(y_test)\n",
    "\n",
    "balance_stats = []\n",
    "balance_stats.extend([{\"dataset\": \"train\",\n",
    "                       \"1\": format(train_balance[\"1\"], \".2%\"),\n",
    "                       \"0\": format(train_balance[\"0\"], \".2%\"),},\n",
    "                      {\"dataset\": \"validation\",\n",
    "                       \"1\": format(val_balance[\"1\"], \".2%\"),\n",
    "                       \"0\": format(val_balance[\"0\"], \".2%\"),},\n",
    "                      {\"dataset\": \"test\",\n",
    "                       \"1\": format(test_balance[\"1\"], \".2%\"),\n",
    "                       \"0\": format(test_balance[\"0\"], \".2%\"),}])\n",
    "\n",
    "display(pd.DataFrame(balance_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3cf716-3e42-47ad-b018-ed8f7c768894",
   "metadata": {},
   "source": [
    "## 6 - Balance with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0985aa-937b-49b9-8836-02e9ad384b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset saved to /mnt/c/Users/Lucas/Documents/Externship/SPLIT-ICML/airline-passenger-satisfaction/train_clean_encoded_balanced.csv\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = train_encoded.drop(columns=[labels]), train_encoded[labels]\n",
    "x_train_balanced, y_train_balanced = dx.smote(x_train, y_train, train_encoded_filename, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e16d33-3767-47a1-8e86-14d50f43deed",
   "metadata": {},
   "source": [
    "## 7 - Run SPLIT -> Depth = 2, max depth = 5, lambda = 0.005-0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cea07c1-e740-416a-8506-0fe42e1a9deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>leaves</th>\n",
       "      <th>training runtime (s)</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>6.03</td>\n",
       "      <td>87.99%</td>\n",
       "      <td>88.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006</td>\n",
       "      <td>6</td>\n",
       "      <td>5.74</td>\n",
       "      <td>87.99%</td>\n",
       "      <td>88.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007</td>\n",
       "      <td>6</td>\n",
       "      <td>5.56</td>\n",
       "      <td>87.99%</td>\n",
       "      <td>88.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008</td>\n",
       "      <td>5</td>\n",
       "      <td>5.64</td>\n",
       "      <td>87.13%</td>\n",
       "      <td>88.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009</td>\n",
       "      <td>5</td>\n",
       "      <td>5.71</td>\n",
       "      <td>87.13%</td>\n",
       "      <td>88.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>5</td>\n",
       "      <td>5.53</td>\n",
       "      <td>87.13%</td>\n",
       "      <td>88.47%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lambda  leaves training runtime (s) training accuracy validation accuracy\n",
       "0   0.005       6                 6.03            87.99%              88.92%\n",
       "1   0.006       6                 5.74            87.99%              88.92%\n",
       "2   0.007       6                 5.56            87.99%              88.92%\n",
       "3   0.008       5                 5.64            87.13%              88.47%\n",
       "4   0.009       5                 5.71            87.13%              88.47%\n",
       "5   0.010       5                 5.53            87.13%              88.47%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iteration 0 -> Lambda = 0.005\n",
    "model_0, tree_0, model_data_0 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.005)\n",
    "train_prediction_0 = dx.prediction_split(model_0, x_train_balanced, y_train_balanced)\n",
    "val_prediction_0 = dx.prediction_split(model_0, x_val, y_val)\n",
    "\n",
    "# Iteration 1 -> Lambda = 0.006\n",
    "model_1, tree_1, model_data_1 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.006)\n",
    "train_prediction_1 = dx.prediction_split(model_1, x_train_balanced, y_train_balanced)\n",
    "val_prediction_1 = dx.prediction_split(model_1, x_val, y_val)\n",
    "\n",
    "# Iteration 2 -> Lambda = 0.007\n",
    "model_2, tree_2, model_data_2 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.007)\n",
    "train_prediction_2 = dx.prediction_split(model_2, x_train_balanced, y_train_balanced)\n",
    "val_prediction_2 = dx.prediction_split(model_2, x_val, y_val)\n",
    "\n",
    "# Iteration 3 -> Lambda = 0.008\n",
    "model_3, tree_3, model_data_3 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.008)\n",
    "train_prediction_3 = dx.prediction_split(model_3, x_train_balanced, y_train_balanced)\n",
    "val_prediction_3 = dx.prediction_split(model_3, x_val, y_val)\n",
    "\n",
    "# Iteration 4 -> Lambda = 0.009\n",
    "model_4, tree_4, model_data_4 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.009)\n",
    "train_prediction_4 = dx.prediction_split(model_4, x_train_balanced, y_train_balanced)\n",
    "val_prediction_4 = dx.prediction_split(model_4, x_val, y_val)\n",
    "\n",
    "# Iteration 5 -> Lambda = 0.01\n",
    "model_5, tree_5, model_data_5 = dx.train_split(x_train_balanced, y_train_balanced, 2, 5, 0.01)\n",
    "train_prediction_5 = dx.prediction_split(model_5, x_train_balanced, y_train_balanced)\n",
    "val_prediction_5 = dx.prediction_split(model_5, x_val, y_val)\n",
    "\n",
    "models_data = [model_data_0, model_data_1, model_data_2, model_data_3, model_data_4, model_data_5]\n",
    "train_predictions = [train_prediction_0, train_prediction_1, train_prediction_2, train_prediction_3, train_prediction_4, train_prediction_5]\n",
    "val_predictions = [val_prediction_0, val_prediction_1, val_prediction_2, val_prediction_3, val_prediction_4, val_prediction_5]\n",
    "\n",
    "split_results = []\n",
    "\n",
    "for i in range(6):\n",
    "    split_results.extend([{\"lambda\": models_data[i][\"lambda\"],\n",
    "                           \"leaves\": models_data[i][\"leaves\"],\n",
    "                           \"training runtime (s)\": format(models_data[i][\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_predictions[i][1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_predictions[i][1], \".2%\"),}])\n",
    "\n",
    "display(pd.DataFrame(split_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c08f194-93fd-45ce-ae18-0f425cc96029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda 0.005 tree: { feature: 0 [ left child: { prediction: 1, loss: 0.0020855057518929243 }, right child: { feature: 8 [ left child: { feature: 1 [ left child: { feature: 3 [ left child: { prediction: 0, loss: 0.039812251925468445 }, right child: { prediction: 1, loss: 0.025176560506224632 }] }, right child: { prediction: 1, loss: 0.03738177567720413 }] }, right child: { feature: 2 [ left child: { prediction: 0, loss: 0.021706968545913696 }, right child: { prediction: 1, loss: 0.0 }] }] }] } \n",
      "\n",
      "lambda 0.006 tree: { feature: 0 [ left child: { prediction: 1, loss: 0.0020855057518929243 }, right child: { feature: 8 [ left child: { feature: 1 [ left child: { feature: 3 [ left child: { prediction: 0, loss: 0.039812251925468445 }, right child: { prediction: 1, loss: 0.025176560506224632 }] }, right child: { prediction: 1, loss: 0.03738177567720413 }] }, right child: { feature: 2 [ left child: { prediction: 0, loss: 0.021706968545913696 }, right child: { prediction: 1, loss: 0.0 }] }] }] } \n",
      "\n",
      "lambda 0.007 tree: { feature: 0 [ left child: { prediction: 1, loss: 0.0020855057518929243 }, right child: { feature: 8 [ left child: { feature: 1 [ left child: { feature: 3 [ left child: { prediction: 0, loss: 0.039812251925468445 }, right child: { prediction: 1, loss: 0.025176560506224632 }] }, right child: { prediction: 1, loss: 0.03738177567720413 }] }, right child: { feature: 2 [ left child: { prediction: 0, loss: 0.021706968545913696 }, right child: { prediction: 1, loss: 0.0 }] }] }] }\n"
     ]
    }
   ],
   "source": [
    "print(\"lambda\",models_data[0][\"lambda\"], \"tree:\", tree_0, \"\\n\")\n",
    "print(\"lambda\",models_data[1][\"lambda\"], \"tree:\", tree_1, \"\\n\")\n",
    "print(\"lambda\",models_data[2][\"lambda\"], \"tree:\", tree_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f27728-ebb6-46e7-b018-cb5638e5fc3d",
   "metadata": {},
   "source": [
    "Despite the different lambdas, the 3 trees are identical. Same number of leaves, same loss, same accuracy. I'm picking lambda = 0.007 because it keeps accuracy and tree size the same while giving the most regularization cushion against small shifts in data and pipeline or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb15b009-3d81-44d3-8962-0ef10b6642e2",
   "metadata": {},
   "source": [
    "## 8 - Run XGBoost -> baseline iteration, cumulative gain = 80%-99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87ca9539-4870-448d-907e-bbc407242ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>92.47%</td>\n",
       "      <td>93.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cumulative gain = 80%</td>\n",
       "      <td>91.47%</td>\n",
       "      <td>92.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cumulative gain = 90%</td>\n",
       "      <td>92.23%</td>\n",
       "      <td>93.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cumulative gain = 95%</td>\n",
       "      <td>92.37%</td>\n",
       "      <td>93.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cumulative gain = 97.5%</td>\n",
       "      <td>92.34%</td>\n",
       "      <td>93.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cumulative gain = 99%</td>\n",
       "      <td>92.34%</td>\n",
       "      <td>93.51%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 iteration training accuracy validation accuracy\n",
       "0                 baseline            92.47%              93.74%\n",
       "1    cumulative gain = 80%            91.47%              92.38%\n",
       "2    cumulative gain = 90%            92.23%              93.43%\n",
       "3    cumulative gain = 95%            92.37%              93.63%\n",
       "4  cumulative gain = 97.5%            92.34%              93.52%\n",
       "5    cumulative gain = 99%            92.34%              93.51%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# baseline\n",
    "xgb_baseline, size_baseline, runtime_baseline = dx.train_xgb(x_train_balanced, y_train_balanced, random_state=RANDOM_SEED)\n",
    "y_train_pred_baseline, acc_baseline = dx.prediction_xgb(xgb_baseline, x_train_balanced, y_train_balanced)\n",
    "y_val_pred_baseline, acc_val_baseline = dx.prediction_xgb(xgb_baseline, x_val, y_val)\n",
    "\n",
    "gain_sorted, total_gain = dx.sort_by_gain(xgb_baseline)\n",
    "\n",
    "# cumulative gain = 80%\n",
    "xgb_0, size_0, runtime_0, features_0 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .8, random_state=RANDOM_SEED)\n",
    "y_train_pred_0, acc_0 = dx.prediction_xgb(xgb_0, x_train_balanced[features_0], y_train_balanced)\n",
    "y_val_pred_0, acc_val_0 = dx.prediction_xgb(xgb_0, x_val[features_0], y_val)\n",
    "\n",
    "# cumulative gain = 90%\n",
    "xgb_1, size_1, runtime_1, features_1 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .9, random_state=RANDOM_SEED)\n",
    "y_train_pred_1, acc_1 = dx.prediction_xgb(xgb_1, x_train_balanced[features_1], y_train_balanced)\n",
    "y_val_pred_1, acc_val_1 = dx.prediction_xgb(xgb_1, x_val[features_1], y_val)\n",
    "\n",
    "# cumulative gain = 95%\n",
    "xgb_2, size_2, runtime_2, features_2 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .95, random_state=RANDOM_SEED)\n",
    "y_train_pred_2, acc_2 = dx.prediction_xgb(xgb_2, x_train_balanced[features_2], y_train_balanced)\n",
    "y_val_pred_2, acc_val_2 = dx.prediction_xgb(xgb_2, x_val[features_2], y_val)\n",
    "\n",
    "# cumulative gain = 97.5%\n",
    "xgb_3, size_3, runtime_3, features_3 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .975, random_state=RANDOM_SEED)\n",
    "y_train_pred_3, acc_3 = dx.prediction_xgb(xgb_3, x_train_balanced[features_3], y_train_balanced)\n",
    "y_val_pred_3, acc_val_3 = dx.prediction_xgb(xgb_3, x_val[features_3], y_val)\n",
    "\n",
    "# cumulative gain = 99%\n",
    "xgb_4, size_4, runtime_4, features_4 = dx.cumulative_gain(x_train_balanced, y_train_balanced, gain_sorted, total_gain, .99, random_state=RANDOM_SEED)\n",
    "y_train_pred_4, acc_4 = dx.prediction_xgb(xgb_4, x_train_balanced[features_4], y_train_balanced)\n",
    "y_val_pred_4, acc_val_4 = dx.prediction_xgb(xgb_4, x_val[features_4], y_val)\n",
    "\n",
    "xgb_iterations = [\"baseline\", \"cumulative gain = 80%\", \"cumulative gain = 90%\",\n",
    "                  \"cumulative gain = 95%\", \"cumulative gain = 97.5%\",  \"cumulative gain = 99%\"]\n",
    "xgb_train_acc = [acc_baseline, acc_0, acc_1, acc_2, acc_3, acc_4]\n",
    "xgb_val_acc = [acc_val_baseline, acc_val_0, acc_val_1, acc_val_2, acc_val_3, acc_val_4]\n",
    "\n",
    "xgb_results = []\n",
    "for i in range(6):\n",
    "    xgb_results.extend([{\"iteration\": xgb_iterations[i],\n",
    "                         \"training accuracy\": format(xgb_train_acc[i],\".2%\"),\n",
    "                         \"validation accuracy\": format(xgb_val_acc[i],\".2%\"),}])\n",
    "\n",
    "display(pd.DataFrame(xgb_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e785a-e76f-42ae-a61f-fd23a88ca906",
   "metadata": {},
   "source": [
    "Both the baseline and the cumulative gain = 99% scenarios yielded the same accuracy. I'll pick the **99% cumulative gain**. Why? It's a simpler model, even if slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8643252-cdfb-437e-aae2-ed9e703ffd68",
   "metadata": {},
   "source": [
    "## 9 - Run SPLIT (lambda = 0.007) with the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3a9669b-887a-4cb5-bf46-b50eca0b211a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>training runtime (s)</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "      <th>testing accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>100 trees, 754 leaves</td>\n",
       "      <td>0.30</td>\n",
       "      <td>92.34%</td>\n",
       "      <td>93.51%</td>\n",
       "      <td>93.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPLIT</td>\n",
       "      <td>6 leaves</td>\n",
       "      <td>5.09</td>\n",
       "      <td>87.99%</td>\n",
       "      <td>88.92%</td>\n",
       "      <td>88.87%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                   size training runtime (s) training accuracy  \\\n",
       "0  XGBoost  100 trees, 754 leaves                 0.30            92.34%   \n",
       "1    SPLIT               6 leaves                 5.09            87.99%   \n",
       "\n",
       "  validation accuracy testing accuracy  \n",
       "0              93.51%           93.63%  \n",
       "1              88.92%           88.87%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_6, tree_6, model_data_6 = dx.train_split(x_train_balanced[features_4], y_train_balanced, 2, 5, 0.007)\n",
    "train_prediction_6 = dx.prediction_split(model_6, x_train_balanced[features_4], y_train_balanced)\n",
    "val_prediction_6 = dx.prediction_split(model_6, x_val[features_4], y_val)\n",
    "test_prediction_6 = dx.prediction_split(model_6, x_test[features_4], y_test)\n",
    "\n",
    "y_test_pred_4, acc_pred_4 = dx.prediction_xgb(xgb_4, x_test[features_4], y_test)\n",
    "\n",
    "split_xgb_results = []\n",
    "split_xgb_results.extend([{\"model\": \"XGBoost\",\n",
    "                           \"size\": str(size_4[\"trees\"]) + \" trees, \" + str(size_4[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(runtime_4, \".2f\"),\n",
    "                           \"training accuracy\": format(acc_4, \".2%\"),\n",
    "                           \"validation accuracy\": format(acc_val_4, \".2%\"),\n",
    "                           \"testing accuracy\": format(acc_pred_4, \".2%\"),},\n",
    "                          {\"model\": \"SPLIT\",\n",
    "                           \"size\": str(model_data_6[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_6[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_6[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_6[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_6[1], \".2%\"),},])\n",
    "\n",
    "display(pd.DataFrame(split_xgb_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4b6ce-7ff5-442b-9b7c-8bbbe9f29ce9",
   "metadata": {},
   "source": [
    "The accuracy didn't improve at all, nor did sparsity. What I'm doing now is applying a different set of parameters I found through tinkering with SPLIT in another notebook (no need to repeat the process here. It was the same trial-and-error process you saw on step 7, but also messing with depth and max depth). I'm using that because it yielded a higher accuracy. But it was with `RANDOM_SEED=42`. We'll see if accuracy remains the same with this seed. If it differs too much, it's a sign the model is not stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e1914-af73-402a-ba24-232fa612b89c",
   "metadata": {},
   "source": [
    "## 9.1 - Run SPLIT (depth = 5, max depth = 6, lambda = 0.005) with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c238893d-bfde-405d-83fe-ca6d5df3b940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>training runtime (s)</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>validation accuracy</th>\n",
       "      <th>testing accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>100 trees, 754 leaves</td>\n",
       "      <td>0.30</td>\n",
       "      <td>92.34%</td>\n",
       "      <td>93.51%</td>\n",
       "      <td>93.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPLIT (depth=2, max depth=5, lambda=0.007)</td>\n",
       "      <td>6 leaves</td>\n",
       "      <td>5.09</td>\n",
       "      <td>87.99%</td>\n",
       "      <td>88.92%</td>\n",
       "      <td>88.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPLIT (depth=5, max depth=6, lambda=0.005)</td>\n",
       "      <td>8 leaves</td>\n",
       "      <td>18.75</td>\n",
       "      <td>89.89%</td>\n",
       "      <td>91.44%</td>\n",
       "      <td>91.83%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        model                   size  \\\n",
       "0                                     XGBoost  100 trees, 754 leaves   \n",
       "1  SPLIT (depth=2, max depth=5, lambda=0.007)               6 leaves   \n",
       "2  SPLIT (depth=5, max depth=6, lambda=0.005)               8 leaves   \n",
       "\n",
       "  training runtime (s) training accuracy validation accuracy testing accuracy  \n",
       "0                 0.30            92.34%              93.51%           93.63%  \n",
       "1                 5.09            87.99%              88.92%           88.87%  \n",
       "2                18.75            89.89%              91.44%           91.83%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_xgb_results.pop()\n",
    "\n",
    "model_7, tree_7, model_data_7 = dx.train_split(x_train_balanced[features_4], y_train_balanced, 5, 6, 0.005)\n",
    "train_prediction_7 = dx.prediction_split(model_7, x_train_balanced[features_4], y_train_balanced)\n",
    "val_prediction_7 = dx.prediction_split(model_7, x_val[features_4], y_val)\n",
    "test_prediction_7 = dx.prediction_split(model_7, x_test[features_4], y_test)\n",
    "\n",
    "split_xgb_results.extend([{\"model\": \"SPLIT (depth=2, max depth=5, lambda=0.007)\",\n",
    "                           \"size\": str(model_data_6[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_6[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_6[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_6[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_6[1], \".2%\"),},\n",
    "                          {\"model\": \"SPLIT (depth=5, max depth=6, lambda=0.005)\",\n",
    "                           \"size\": str(model_data_7[\"leaves\"]) + \" leaves\",\n",
    "                           \"training runtime (s)\": format(model_data_7[\"runtime\"], \".2f\"),\n",
    "                           \"training accuracy\": format(train_prediction_7[1], \".2%\"),\n",
    "                           \"validation accuracy\": format(val_prediction_7[1], \".2%\"),\n",
    "                           \"testing accuracy\": format(test_prediction_7[1], \".2%\"),},])\n",
    "\n",
    "display(pd.DataFrame(split_xgb_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e0492-8bc1-42bb-81d8-9b957874d06b",
   "metadata": {},
   "source": [
    "As expected, accuracy went up sharply here, and the gap narrowed significantly, especially in validation and testing (though not as much as with `RANDOM_SEED=42`). For this random seed, SPLIT with depth 5, max depth 6 and lambda 0.005 is the more accurate option. Below, its tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4026d77f-30d6-4c34-bf41-d13ae46393c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ feature: 4 [ left child: { prediction: 1, loss: 0.0020855057518929243 }, right child: { feature: 2 [ left child: { feature: 1 [ left child: { feature: 8 [ left child: { feature: 5 [ left child: { prediction: 0, loss: 0.13360905647277832 }, right child: { prediction: 1, loss: 0.046756159514188766 }] }, right child: { feature: 10 [ left child: { prediction: 1, loss: 0.0754198282957077 }, right child: { prediction: 0, loss: 0.04452279955148697 }] }] }, right child: { prediction: 1, loss: 0.012774600647389889 }] }, right child: { feature: 6 [ left child: { prediction: 0, loss: 0.07867606729269028 }, right child: { prediction: 1, loss: 0 }] }] }] }\n"
     ]
    }
   ],
   "source": [
    "print(tree_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876fbc9-3d8d-4037-8356-f37cc6a0a945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
